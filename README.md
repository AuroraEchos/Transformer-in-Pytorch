# Transformer (PyTorch å®ç°)

è¯¥ä»“åº“æä¾›äº†ä¸€ä¸ªåŸºäº PyTorch çš„ Transformer æ¨¡å‹å®ç°ï¼Œä»£ç ç»“æ„æ¸…æ™°ã€æ¨¡å—åŒ–ï¼Œå®Œæ•´å¤ç°äº†è®ºæ–‡ ["Attention Is All You Need"](https://arxiv.org/abs/1706.03762) ä¸­çš„æ¶æ„ã€‚

## âœ¨ ç‰¹æ€§
- å®Œå…¨æ¨¡å—åŒ–è®¾è®¡ï¼š
  - PositionalEncodingï¼ˆä½ç½®ç¼–ç ï¼‰
  - ScaledDotProductAttentionï¼ˆç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ï¼‰
  - MultiHeadAttentionï¼ˆå¤šå¤´æ³¨æ„åŠ›ï¼‰
  - PositionwiseFeedForwardï¼ˆä½ç½®å‰é¦ˆç½‘ç»œï¼‰
  - EncoderLayerï¼ˆç¼–ç å™¨å±‚ï¼‰
  - DecoderLayerï¼ˆè§£ç å™¨å±‚ï¼‰
  - Encoderï¼ˆç¼–ç å™¨å †å ï¼‰
  - Decoderï¼ˆè§£ç å™¨å †å ï¼‰
  - Transformerï¼ˆå®Œæ•´æ¨¡å‹ï¼‰
- æ”¯æŒä»»æ„åºåˆ—åˆ°åºåˆ—ä»»åŠ¡ï¼ˆä¾‹å¦‚æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦ç­‰ï¼‰
- æ˜“äºæ‰©å±•å’Œè‡ªå®šä¹‰ï¼ˆä¾‹å¦‚æ·»åŠ  label smoothingã€å…±äº«åµŒå…¥å±‚ï¼‰

## ğŸ“ ç¯å¢ƒä¾èµ–
- Python 3.7+
- PyTorch >= 1.10

å®‰è£…ä¾èµ–ï¼š
```bash
pip install torch
